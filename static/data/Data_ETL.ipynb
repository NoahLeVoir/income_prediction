{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in our ETL process is to extract the data gathered for ....\n",
    "\n",
    "The first step in the extract phase of this ETL is to import the needed frameworks to run the script in this jupyter notebook. Here we import:\n",
    "\n",
    "- a\n",
    "- b\n",
    "- C\n",
    "\n",
    "The below cell contains all of these imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder - MIGHT NOT NEED\n",
    "Before running the first cell, please ensure you have created your table in pgAdmin and added your config.py file with your username and password information.\n",
    "\n",
    "More instructions on how to do this can be found in the readME of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# This will ignore the pink warning blocks from jupyter notebook from cluttering the workspace\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract CSV\n",
    "Here we will load the csv files that are located in the \"Resources\" folder of this repo. To do this step we will set each files pathway to its' own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to load\n",
    "csv = \"Resources/adult.data\"\n",
    "\n",
    "# Read to a df\n",
    "# Because there is no header in this dataset we will set it to \"None\" on the read in\n",
    "data_df = pd.read_csv(csv, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see that everything loaded in properly\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will use the pandas \".read_csv\" functionality to read each of our csv's into a dataframe. This allows us to prepare for the transform step as we can now see the data of each csv cleanly presented through the power of the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T - Transform\n",
    "Next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column names per UCI data description\n",
    "data_df.columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_number\", \"marital_status\", \"occupation\",\\\n",
    "                  \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\\\n",
    "                  \"income\"]\n",
    "\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L - Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the new dataframe into a new csv file in our data folder\n",
    "# data_df.to_csv(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database connection\n",
    "In this step we will be connecting to the database that was made in pgAdmin before this jupyter notebook was run.\n",
    "\n",
    "chocolate cake recipe incase we want to do this kind of thing for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Username and Password for pgAdmin\n",
    "# Also update Database Name to match what you created at the start\n",
    "connection_string = f\"{username}:{password}@localhost:5432/database name...\"\n",
    "\n",
    "# Create the engine\n",
    "engine = create_engine(f'postgresql://{connection_string}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure everything was set up and the config.py file is running correctly, see if you get the correct names to return back from the engine that is connected to your pgAdmin database!\n",
    "\n",
    "You should see:Â  ['....']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm tables\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataFrames into database\n",
    "Using the pandas function \".to_sql\" we can load the data frames we transformed in this jupyter notebook to our connected engine. If all of the steps have been followed up to this point, after running the next few cells, you can switch over to pgAdmin to query your new fully populated tables!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe\n",
    "df.to_sql(name='name', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sqlalchemy we can run a query here in the notebook to confirm data has been loaded to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the 'name' table which should contain the df data\n",
    "pd.read_sql_query('SELECT * FROM name', con=engine).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
